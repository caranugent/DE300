{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32dd3cf7-18cd-45a8-a62c-c814a753b05c",
      "metadata": {
        "id": "32dd3cf7-18cd-45a8-a62c-c814a753b05c"
      },
      "source": [
        "# ðŸ—‚ï¸ MapReduce Tutorial\n",
        "## 1. ðŸ” What is MapReduce?\n",
        "MapReduce is a programming model designed to process large-scale data in a distributed and parallel fashion.\n",
        "\n",
        "It consists of three major phases:\n",
        "\n",
        "- Map: Process input data and output intermediate key-value pairs.\n",
        "\n",
        "- Shuffle/Sort: Group all intermediate values by their key.\n",
        "\n",
        "- Reduce: Aggregate the values associated with each key to produce the final outputâ€‹"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b06952-0def-41ff-a8c2-fdb067e894ab",
      "metadata": {
        "id": "a7b06952-0def-41ff-a8c2-fdb067e894ab"
      },
      "source": [
        "## 2. MapReduce Use Case: Word Count\n",
        "### 2.1 Map Phase\n",
        "1. Read input data line by line.\n",
        "2. Tokenize each line into words.\n",
        "3. Emit (word, 1) for each word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9b239cb-4e51-4ef3-82b5-e32058c9b32b",
      "metadata": {
        "id": "c9b239cb-4e51-4ef3-82b5-e32058c9b32b"
      },
      "outputs": [],
      "source": [
        "def map_phase(input_file):\n",
        "    \"\"\"Reads lines from input_file, yields (word, 1) for each word.\"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        for line in f:\n",
        "            words = line.strip().split()\n",
        "            for word in words:\n",
        "                yield (word.lower(), 1)   # Convert to lower case"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba7e57ef-04a1-4b85-a227-053db1232828",
      "metadata": {
        "id": "ba7e57ef-04a1-4b85-a227-053db1232828"
      },
      "source": [
        "### 2.2 Shuffle/Sort Phase\n",
        "We need to group by the key (the word)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15e4acd2-69f3-4713-9fe2-7e74c85ac3fb",
      "metadata": {
        "id": "15e4acd2-69f3-4713-9fe2-7e74c85ac3fb"
      },
      "outputs": [],
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    \"\"\"Groups the mapped data by key (word).\"\"\"\n",
        "    sorted_data = {}\n",
        "    for key, value in mapped_data:\n",
        "        if key not in sorted_data:\n",
        "            sorted_data[key] = []\n",
        "        sorted_data[key].append(value)\n",
        "    return sorted_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0867244-a341-41ff-bd67-b593e8fca84a",
      "metadata": {
        "id": "a0867244-a341-41ff-bd67-b593e8fca84a"
      },
      "source": [
        "### 2.3 Reduce Phase\n",
        "For each word (key), we want to sum up the counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2ac1cae-a003-4c63-858a-77212c034932",
      "metadata": {
        "id": "d2ac1cae-a003-4c63-858a-77212c034932"
      },
      "outputs": [],
      "source": [
        "def reduce_phase(shuffled_data):\n",
        "    \"\"\"For each word key, sum up all the values.\"\"\"\n",
        "    reduced_data = {}\n",
        "    for key, values in shuffled_data.items():\n",
        "        reduced_data[key] = sum(values)\n",
        "    return reduced_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4745af-1623-4bfa-a14f-62ac6aa9b13e",
      "metadata": {
        "id": "9c4745af-1623-4bfa-a14f-62ac6aa9b13e"
      },
      "source": [
        "### 2.4 Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ff88b289-7ca9-46cc-8590-c3b65a5f799a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff88b289-7ca9-46cc-8590-c3b65a5f799a",
        "outputId": "9cb2e739-e36c-4bb2-bb58-ee16e254ac97",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new: 4\n",
            "pope: 12\n",
            "leo: 11\n",
            "xiv: 5\n",
            "cites: 1\n",
            "aiâ€™s: 1\n",
            "challenge: 1\n",
            "to: 14\n",
            "human: 4\n",
            "dignity: 1\n",
            "in: 16\n",
            "his: 8\n",
            "name: 6\n",
            "choice: 2\n",
            "named: 1\n",
            "himself: 1\n",
            "after: 1\n",
            "another: 2\n",
            "with: 2\n",
            "a: 8\n",
            "legacy: 1\n",
            "of: 23\n",
            "social: 6\n",
            "reform.: 1\n",
            "by: 2\n",
            "cecily: 1\n",
            "mauran: 1\n",
            "on: 6\n",
            "may: 1\n",
            "11,: 1\n",
            "2025: 2\n",
            "the: 34\n",
            "carries: 1\n",
            "symbolism: 1\n",
            "for: 7\n",
            "values: 1\n",
            "he: 4\n",
            "wishes: 1\n",
            "emulate,: 1\n",
            "recognition: 1\n",
            "most: 1\n",
            "pressing: 1\n",
            "issues: 1\n",
            "sees: 2\n",
            "as: 5\n",
            "leader: 1\n",
            "catholic: 4\n",
            "church.: 1\n",
            "xiv,: 1\n",
            "artificial: 2\n",
            "intelligence: 2\n",
            "is: 3\n",
            "at: 1\n",
            "heart: 1\n",
            "choice.: 1\n",
            "born: 1\n",
            "robert: 1\n",
            "francis: 1\n",
            "prevost,: 1\n",
            "chose: 2\n",
            "papal: 1\n",
            "reference: 1\n",
            "xiii: 4\n",
            "(1810-1903): 1\n",
            "who: 1\n",
            "presided: 1\n",
            "over: 1\n",
            "church: 3\n",
            "during: 2\n",
            "industrial: 3\n",
            "revolution,: 1\n",
            "which: 2\n",
            "ushered: 1\n",
            "massive: 1\n",
            "upheaval.: 1\n",
            "ai: 5\n",
            "boom: 1\n",
            "similar: 1\n",
            "moment: 1\n",
            "rapid: 1\n",
            "societal: 1\n",
            "change.: 1\n",
            "address: 2\n",
            "college: 1\n",
            "cardinals: 1\n",
            "saturday,: 1\n",
            "explained: 1\n",
            "choice,: 1\n",
            "explicitly: 1\n",
            "mentioning: 1\n",
            "parallels: 1\n",
            "these: 2\n",
            "two: 1\n",
            "cataclysmic: 1\n",
            "eras:: 1\n",
            "sensing: 1\n",
            "myself: 1\n",
            "called: 2\n",
            "continue: 1\n",
            "this: 1\n",
            "same: 1\n",
            "path,: 1\n",
            "i: 1\n",
            "take: 1\n",
            "xiv.: 1\n",
            "there: 1\n",
            "are: 1\n",
            "different: 1\n",
            "reasons: 1\n",
            "this,: 1\n",
            "but: 1\n",
            "mainly: 1\n",
            "because: 1\n",
            "historic: 1\n",
            "encyclical: 1\n",
            "rerum: 2\n",
            "novarum: 2\n",
            "addressed: 1\n",
            "question: 1\n",
            "context: 1\n",
            "first: 1\n",
            "great: 1\n",
            "revolution.: 1\n",
            "our: 1\n",
            "own: 1\n",
            "day,: 1\n",
            "offers: 1\n",
            "everyone: 1\n",
            "treasury: 1\n",
            "her: 1\n",
            "teaching: 1\n",
            "response: 1\n",
            "revolution: 1\n",
            "and: 14\n",
            "developments: 1\n",
            "field: 1\n",
            "that: 1\n",
            "pose: 1\n",
            "challenges: 1\n",
            "defence: 1\n",
            "dignity,: 1\n",
            "justice: 1\n",
            "labour.: 1\n",
            "was: 1\n",
            "known: 1\n",
            "focusing: 1\n",
            "inequality: 1\n",
            "labor: 2\n",
            "rights: 3\n",
            "industrialization: 1\n",
            "period: 1\n",
            "workers: 1\n",
            "moved: 1\n",
            "away: 1\n",
            "from: 1\n",
            "individual: 2\n",
            "craftsmanship: 1\n",
            "farm: 1\n",
            "work: 1\n",
            "into: 1\n",
            "mass: 1\n",
            "production: 1\n",
            "factories: 1\n",
            "under: 1\n",
            "harsh,: 1\n",
            "low-wage: 1\n",
            "conditions.: 1\n",
            "yet: 1\n",
            "also: 2\n",
            "emphasized: 1\n",
            "rejected: 1\n",
            "socialism.: 1\n",
            "encyclical,: 1\n",
            "or: 2\n",
            "formal: 1\n",
            "letter: 1\n",
            "church,: 1\n",
            "balance: 1\n",
            "between: 1\n",
            "\"the: 1\n",
            "duties: 1\n",
            "capital: 1\n",
            "labor,\": 1\n",
            "subtitle: 1\n",
            "address.: 1\n",
            "follow: 1\n",
            "footsteps: 1\n",
            "previous: 1\n",
            "reformer: 1\n",
            "powerful: 1\n",
            "message: 2\n",
            "industry: 1\n",
            "its: 1\n",
            "impact: 1\n",
            "global: 1\n",
            "workforce.: 1\n",
            "modern: 1\n",
            "society: 1\n",
            "has: 2\n",
            "already: 2\n",
            "seen: 1\n",
            "effects: 1\n",
            "through: 1\n",
            "job: 1\n",
            "replacement: 1\n",
            "exploitation: 1\n",
            "data: 1\n",
            "labelers.: 1\n",
            "according: 1\n",
            "world: 1\n",
            "economic: 1\n",
            "forum's: 1\n",
            "jobs: 1\n",
            "report,: 1\n",
            "41: 1\n",
            "percent: 1\n",
            "employers: 1\n",
            "intend: 1\n",
            "downsize: 1\n",
            "their: 1\n",
            "workforce: 1\n",
            "favor: 1\n",
            "automating: 1\n",
            "tasks: 1\n",
            "ai.: 2\n",
            "international: 1\n",
            "organization: 1\n",
            "published: 2\n",
            "2024: 1\n",
            "report: 1\n",
            "highlighting: 1\n",
            "\"invisible: 1\n",
            "labor\": 1\n",
            "development: 1\n",
            "low-wages: 1\n",
            "limited: 1\n",
            "protections: 1\n",
            "workers.: 1\n",
            "weighed: 1\n",
            "other: 1\n",
            "consequences: 1\n",
            "francis,: 1\n",
            "leo's: 1\n",
            "predecessor,: 1\n",
            "january: 1\n",
            "2024,: 1\n",
            "warning: 1\n",
            "about: 1\n",
            "\"distortion: 1\n",
            "reality: 1\n",
            "partially: 1\n",
            "completely: 1\n",
            "false: 1\n",
            "narratives,: 1\n",
            "believed: 1\n",
            "broadcast: 1\n",
            "if: 1\n",
            "they: 1\n",
            "were: 1\n",
            "true.\": 1\n",
            "more: 1\n",
            "recently,: 1\n",
            "francis': 1\n",
            "final: 1\n",
            "before: 1\n",
            "died: 1\n",
            "reflected: 1\n",
            "technology: 1\n",
            "replacing: 1\n",
            "interaction.: 1\n"
          ]
        }
      ],
      "source": [
        "# 1. Map\n",
        "mapped = map_phase(\"input.txt\")\n",
        "\n",
        "# 2. Shuffle/Sort\n",
        "shuffled = shuffle_and_sort(mapped)\n",
        "\n",
        "# 3. Reduce\n",
        "reduced_result = reduce_phase(shuffled)\n",
        "\n",
        "# Print or save results\n",
        "for word, count in reduced_result.items():\n",
        "    print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de1ba85-7926-4b45-8ceb-1394ff2ad6ad",
      "metadata": {
        "id": "3de1ba85-7926-4b45-8ceb-1394ff2ad6ad"
      },
      "source": [
        "## 3. MapReduce Use Case: Calculate Mean and Variance\n",
        "### 3.1 Map Phase: Each input data point emits `(value, valueÂ², count=1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1c97da95-b65a-41fa-afd9-d60123cd6bb2",
      "metadata": {
        "id": "1c97da95-b65a-41fa-afd9-d60123cd6bb2"
      },
      "outputs": [],
      "source": [
        "def map_phase(input_file):\n",
        "    \"\"\"Reads numbers from input_file and emits (x, x^2, 1) for each number.\"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        for line in f:\n",
        "            number = float(line.strip())  # Convert string to float\n",
        "            yield (number, number ** 2, 1)  # Emit (x, xÂ², count=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f818fc34-8ae0-41d6-aee9-81f6155c817e",
      "metadata": {
        "id": "f818fc34-8ae0-41d6-aee9-81f6155c817e"
      },
      "source": [
        "### 3.2 Shuffle/Sort: Groups all mapped values together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ed95d51d-c8d2-4bc5-858b-5e3f8dfde650",
      "metadata": {
        "id": "ed95d51d-c8d2-4bc5-858b-5e3f8dfde650"
      },
      "outputs": [],
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    \"\"\"Since we are computing global statistics, this simply collects all mapped data.\"\"\"\n",
        "    sum_x = 0\n",
        "    sum_x2 = 0\n",
        "    count = 0\n",
        "    for x, x2, c in mapped_data:\n",
        "        sum_x += x\n",
        "        sum_x2 += x2\n",
        "        count += c\n",
        "    return sum_x, sum_x2, count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0f0122-94fe-4bd1-a45b-ff4efff18d8c",
      "metadata": {
        "id": "bc0f0122-94fe-4bd1-a45b-ff4efff18d8c"
      },
      "source": [
        "### 3.3 Reduce Step: Compute sum, sum of squares, and count to derive the mean and variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dc6c05c6-550c-421f-b88d-b16f11b91dc6",
      "metadata": {
        "id": "dc6c05c6-550c-421f-b88d-b16f11b91dc6"
      },
      "outputs": [],
      "source": [
        "def reduce_phase(shuffled_data):\n",
        "    \"\"\"Computes mean and variance from aggregated data.\"\"\"\n",
        "    sum_x, sum_x2, count = shuffled_data\n",
        "    if count == 0:\n",
        "        return None, None  # Avoid division by zero\n",
        "\n",
        "    mean = sum_x / count\n",
        "    variance = (sum_x2 / count) - (mean ** 2)\n",
        "\n",
        "    return mean, variance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c83c4f7-c36f-4a18-a415-50b6817c7bbd",
      "metadata": {
        "id": "9c83c4f7-c36f-4a18-a415-50b6817c7bbd"
      },
      "source": [
        "### 3.4 Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb39a925-3a28-4e83-8d99-3ad43718bdfe",
      "metadata": {
        "id": "eb39a925-3a28-4e83-8d99-3ad43718bdfe"
      },
      "outputs": [],
      "source": [
        "# 1. Map Phase\n",
        "mapped = map_phase(\"numbers.txt\")  # Input file with numbers\n",
        "\n",
        "# 2. Shuffle & Sort Phase\n",
        "shuffled = shuffle_and_sort(mapped)\n",
        "\n",
        "# 3. Reduce Phase\n",
        "mean, variance = reduce_phase(shuffled)\n",
        "\n",
        "# Print Results\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Variance: {variance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b669d6bb-f6d4-4093-b648-911e0717bd85",
      "metadata": {
        "id": "b669d6bb-f6d4-4093-b648-911e0717bd85"
      },
      "source": [
        "## 4. MapReduce Use Case: Linear Regression\n",
        "We want to fit a linear model: $$y = mx + b$$ using gradient descent, which iteratively updates parameters m (slope) and b (intercept) based on the gradient: $$m:= m - \\alpha \\frac{1}{N}\\sum_i((mx_i+b-y_i)x_i)$$\n",
        "where:\n",
        "- $\\alpha$ is the learning rate.\n",
        "- $N$ is the number of data points.\n",
        "\n",
        "### 4.1 Mapper Function\n",
        "Each mapper reads a subset of the data and computes the partial gradients for m and b:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa23162a-2d85-4ff2-a10e-b3624c2f8f3d",
      "metadata": {
        "id": "fa23162a-2d85-4ff2-a10e-b3624c2f8f3d"
      },
      "outputs": [],
      "source": [
        "def map_phase(input_file, m, b):\n",
        "    \"\"\"Computes the partial gradients for m and b for each chunk.\"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        for line in f:\n",
        "            x, y = map(float, line.strip().split(','))  # Read X and Y\n",
        "            error = (m * x + b) - y  # Compute error\n",
        "            gradient_m = error * x   # Partial derivative w.r.t. m\n",
        "            gradient_b = error       # Partial derivative w.r.t. b\n",
        "            yield (1, (gradient_m, gradient_b, 1))  # Emit (key=1, values=(âˆ‚m, âˆ‚b, count=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f42bb9d-21b0-42de-b51d-131acfd42888",
      "metadata": {
        "id": "0f42bb9d-21b0-42de-b51d-131acfd42888"
      },
      "source": [
        "### 4.2 Shuffle & Sort Phase\n",
        "This step groups all partial gradients from different mappers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1080be-6053-48f1-ba46-ae9b38fee528",
      "metadata": {
        "id": "2a1080be-6053-48f1-ba46-ae9b38fee528"
      },
      "outputs": [],
      "source": [
        "def shuffle_and_sort(mapped_data):\n",
        "    \"\"\"Aggregates partial gradients from all mappers.\"\"\"\n",
        "    sum_gradient_m = sum_gradient_b = count = 0\n",
        "    for _, (gradient_m, gradient_b, c) in mapped_data:\n",
        "        sum_gradient_m += gradient_m\n",
        "        sum_gradient_b += gradient_b\n",
        "        count += c\n",
        "    return sum_gradient_m, sum_gradient_b, count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ace3da5-63b3-420e-91c7-bbc56431b11b",
      "metadata": {
        "id": "0ace3da5-63b3-420e-91c7-bbc56431b11b"
      },
      "source": [
        "### 4.3 Reducer Function\n",
        "The reducer aggregates the gradients and updates m and b:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7836007-cd98-4504-9d8e-f186a9416d8b",
      "metadata": {
        "id": "e7836007-cd98-4504-9d8e-f186a9416d8b"
      },
      "outputs": [],
      "source": [
        "def reduce_phase(shuffled_data, m, b, alpha):\n",
        "    \"\"\"Updates m and b using the averaged gradients.\"\"\"\n",
        "    sum_gradient_m, sum_gradient_b, count = shuffled_data\n",
        "    if count == 0:\n",
        "        return m, b  # Avoid division by zero\n",
        "\n",
        "    # Compute the average gradients\n",
        "    avg_gradient_m = sum_gradient_m / count\n",
        "    avg_gradient_b = sum_gradient_b / count\n",
        "\n",
        "    # Update parameters using gradient descent\n",
        "    m -= alpha * avg_gradient_m\n",
        "    b -= alpha * avg_gradient_b\n",
        "\n",
        "    return m, b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee2f58c-fd57-4f62-8218-f4d46b250db9",
      "metadata": {
        "id": "fee2f58c-fd57-4f62-8218-f4d46b250db9"
      },
      "source": [
        "### 4.4 Put It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dc0b1e-485c-4d11-a9d4-7472d47934d5",
      "metadata": {
        "id": "c9dc0b1e-485c-4d11-a9d4-7472d47934d5"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "iterations = 500  # Number of iterations\n",
        "\n",
        "# Initialize parameters\n",
        "m, b = 0.0, 0.0  # Initial guess\n",
        "\n",
        "# Run gradient descent for multiple iterations\n",
        "for i in range(iterations):\n",
        "    print(f\"Iteration {i+1}: m = {m:.4f}, b = {b:.4f}\")\n",
        "\n",
        "    # Step 1: Map (Compute Partial Gradients)\n",
        "    mapped = map_phase(\"data.csv\", m, b)\n",
        "\n",
        "    # Step 2: Shuffle & Sort (Aggregate Gradients)\n",
        "    shuffled = shuffle_and_sort(mapped)\n",
        "\n",
        "    # Step 3: Reduce (Update Parameters)\n",
        "    m, b = reduce_phase(shuffled, m, b, alpha)\n",
        "\n",
        "# Final Model\n",
        "print(f\"Final Linear Regression Model: y = {m:.4f}x + {b:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bf004e-fd4a-4784-91e8-2781ef1282e3",
      "metadata": {
        "id": "f5bf004e-fd4a-4784-91e8-2781ef1282e3"
      },
      "source": [
        "## 5. âœ… Advantages and Limitations\n",
        "âœ… Advantages\n",
        "- Simplifies parallel programming.\n",
        "\n",
        "- Scales horizontally across distributed systems.\n",
        "\n",
        "- Built-in fault tolerance.\n",
        "\n",
        "âŒ Limitations\n",
        "- Poor performance for iterative or real-time algorithms.\n",
        "\n",
        "- Less flexible than general-purpose distributed computing frameworksâ€‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da7172a-c93b-4cee-89b3-2e904962679a",
      "metadata": {
        "id": "4da7172a-c93b-4cee-89b3-2e904962679a"
      },
      "source": [
        "## Homework Assignments\n",
        "Please use the same `input.txt` file in section 2, modify mapper/ Reducer function to count all the words with length $>=4$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modified mapper function to count all the words with length  >=4:\n",
        "\n",
        "def map_phase(input_file):\n",
        "    \"\"\"Reads lines from input_file, yields 1 for each word w/ len >= 4.\"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        for line in f:\n",
        "            words = line.strip().split()\n",
        "            for word in words:\n",
        "                if len(word) >= 4:\n",
        "                  yield 1   # yield count (1)"
      ],
      "metadata": {
        "id": "LXHNdefg1uvL"
      },
      "id": "LXHNdefg1uvL",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified reducer function to count all the words with length  >=4:\n",
        "\n",
        "def reduce_phase(mapped_data):\n",
        "    \"\"\"Computes sum of data.\"\"\"\n",
        "    return sum(mapped_data)"
      ],
      "metadata": {
        "id": "gkLt0Frx1rKd"
      },
      "id": "gkLt0Frx1rKd",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LAB 06: count all words with length >= 4\n",
        "\n",
        "# 1. Map\n",
        "mapped = list(map_phase(\"input.txt\"))\n",
        "\n",
        "# 2. Reduce\n",
        "reduced_result = reduce_phase(mapped)\n",
        "\n",
        "# Print or save results\n",
        "print(f\"{reduced_result} words with length >= 4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPUbBBpq1RNO",
        "outputId": "f5cdcf50-af15-411f-bcbf-5d817be06652"
      },
      "id": "WPUbBBpq1RNO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290 words with length >= 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92uW1kEN4kXc"
      },
      "id": "92uW1kEN4kXc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}